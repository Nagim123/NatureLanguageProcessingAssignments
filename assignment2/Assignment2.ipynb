{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvig’s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementations"
      ],
      "metadata": {
        "id": "Po4Pu-J5uR7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "f8uLE6LJv38x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [],
      "source": [
        "class AbstractSpellCorrector:\n",
        "    \"\"\"\n",
        "    Abstarct class for any spell corrector\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences: list[list[str]]) -> None:\n",
        "        \"\"\"\n",
        "        Train spell corrector by providing sentences with correct grammar\n",
        "\n",
        "        Parameters:\n",
        "            sentences (list[list[str]]): List of sentences\n",
        "        \"\"\"\n",
        "        raise Exception(\"Not implemented\")\n",
        "\n",
        "    def correct_sentence(self, sentence: list[str]) -> list[str]:\n",
        "        \"\"\"\n",
        "        Correct sentence with errors\n",
        "\n",
        "        Parameters:\n",
        "            sentence (list[str]): List of words\n",
        "        Returns:\n",
        "            (list[str]): List of corrected words\n",
        "        \"\"\"\n",
        "        raise Exception(\"Not implemented\")\n",
        "\n",
        "    def correct_text(self, text: list[list[str]]) -> list[list[str]]:\n",
        "        \"\"\"\n",
        "        Corrects the whole text\n",
        "\n",
        "        Parameters:\n",
        "            text (list[list[str]]): The text to correct\n",
        "        Returns:\n",
        "            (list[list[str]]): Corrected text\n",
        "        \"\"\"\n",
        "        corrected_text = []\n",
        "        for sentence in text:\n",
        "            corrected_text.append(self.correct_sentence(sentence))\n",
        "        return corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Norvig's spell corrector"
      ],
      "metadata": {
        "id": "tdTEHrD4uvyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NorvigSpellCorrector(AbstractSpellCorrector):\n",
        "    \"\"\"\n",
        "    Implementation of Norvig's spell corrector\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences: list[list[str]]) -> None:\n",
        "        text = []\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                text.append(word)\n",
        "        self.word_counter = Counter(text)\n",
        "        self.N = sum(self.word_counter.values())\n",
        "\n",
        "    def correct_sentence(self, sentence: list[str]) -> list[str]:\n",
        "        corrected = []\n",
        "        for word in sentence:\n",
        "            corrected.append(self.__correct_word(word))\n",
        "        return corrected\n",
        "\n",
        "    def __get_word_probability(self, word: str) -> float:\n",
        "        \"\"\"\n",
        "        Get probability of `word`.\n",
        "\n",
        "        Parameters:\n",
        "            word (str): The word\n",
        "        Returns\n",
        "            (float): Probability of occuring of these word in the sentence\n",
        "        \"\"\"\n",
        "        return self.word_counter[word] / self.N\n",
        "\n",
        "    def __correct_word(self, word: str) -> str:\n",
        "        \"\"\"\n",
        "        Correct word by suggesting most probable spelling correction for word\n",
        "\n",
        "        Parameters:\n",
        "            word (str): The word to correct\n",
        "        Returns:\n",
        "            (str): Corrected word\n",
        "        \"\"\"\n",
        "        return max(self._generate_candidates(word), key=self.__get_word_probability)\n",
        "\n",
        "    def _generate_candidates(self, word: str) -> set[str]:\n",
        "        \"\"\"\n",
        "        Generate possible spelling corrections for word\n",
        "\n",
        "        Parameters:\n",
        "            word (str): Word for suggesting corrections\n",
        "        Returns:\n",
        "            (set[str]): Correction candidates\n",
        "        \"\"\"\n",
        "        return (self._extract_known([word]) or self._extract_known(self._get_edits1(word)) or self._extract_known(self._get_edits2(word)) or [word])\n",
        "\n",
        "    def _extract_known(self, words: list[str]|set[str]) -> set[str]:\n",
        "        \"\"\"\n",
        "        The subset of `words` that appear in the dictionary of WORDS.\n",
        "\n",
        "        Parameters:\n",
        "            words (list[str] | set[str]): Collection of words\n",
        "        Returns:\n",
        "            (set[str]): Set of only known worlds\n",
        "        \"\"\"\n",
        "        return set(word for word in words if word in self.word_counter)\n",
        "\n",
        "    def _get_edits1(self, word: str) -> set[str]:\n",
        "        \"\"\"\n",
        "        Get all edits that are one edit away from `word`.\n",
        "\n",
        "        Parameters:\n",
        "            word (str): The word to edit\n",
        "        Returns:\n",
        "            (set[str]): All words edits\n",
        "        \"\"\"\n",
        "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "    def _get_edits2(self, word: str) -> list[str]:\n",
        "        \"\"\"\n",
        "        Get all edits that are two edits away from `word`.\n",
        "\n",
        "        Parameters:\n",
        "            word (str): The word to edit\n",
        "        Returns:\n",
        "            (set[str]): All words edits\n",
        "        \"\"\"\n",
        "        return [e2 for e1 in self._get_edits1(word) for e2 in self._get_edits1(e1)]"
      ],
      "metadata": {
        "id": "A-OFBJtG-Xx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom spell corrector"
      ],
      "metadata": {
        "id": "7RDco-H2ul6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "\n",
        "class CustomSpellCorrector(NorvigSpellCorrector):\n",
        "    \"\"\"\n",
        "    My upgraded Norvig's spell checker.\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences: list[list[str]], n:int = 3, penalty1: int = 0.05, penalty2: int = 0.1) -> None:\n",
        "        \"\"\"\n",
        "        Train spell corrector by providing sentences with correct grammar\n",
        "\n",
        "        Parameters:\n",
        "            sentences (list[list[str]]): List of sentences\n",
        "            n (int): Which n-grams to consider in language model (if n = 2 then unigrams and bigrams will be taken into account)\n",
        "            penalty1 (int): Penalty for 1 distance edits of words\n",
        "            penalty2 (int): Penalty for 2 distance edits of words\n",
        "        \"\"\"\n",
        "        super().__init__(sentences)\n",
        "\n",
        "        self.n = n\n",
        "        self.penalty1 = penalty1\n",
        "        self.penalty2 = penalty2\n",
        "\n",
        "        ngrams = []\n",
        "        for sentence in sentences:\n",
        "            for k in range(2, n+1):\n",
        "                for i in range(0, len(sentence)-k+2):\n",
        "                    if i < len(sentence)-k+1:\n",
        "                        ngram = sentence[i:i+k]\n",
        "                        ngrams.append(\" \".join(ngram))\n",
        "\n",
        "                    ngram_without_last = sentence[i:i+k-1]\n",
        "                    ngrams.append(\" \".join(ngram_without_last))\n",
        "        self.ngram_counter = Counter(ngrams)\n",
        "        self.vocab_size = len(Counter(self.word_counter).keys())\n",
        "\n",
        "    def correct_sentence(self, sentence: list[str]) -> list[str]:\n",
        "        corrected = []\n",
        "        for i in range(len(sentence)):\n",
        "            corrected.append(self.__correct_word(i, sentence))\n",
        "        return corrected\n",
        "\n",
        "    def change_penalties(self, penalty1: int, penalty2: int) -> None:\n",
        "        \"\"\"\n",
        "        Change penalties for 1 distance and 2 distance edits\n",
        "\n",
        "        Parameters:\n",
        "            penalty1 (int): Penalty for 1 distance edits\n",
        "            penalty2 (int): Penalty for 2 distance edits\n",
        "        \"\"\"\n",
        "        self.penalty1 = penalty1\n",
        "        self.penalty2 = penalty2\n",
        "\n",
        "    def __correct_word(self, position: int, sentence: list[str]) -> str:\n",
        "        word = sentence[position]\n",
        "        candidates = [(self.__get_sentence_probability(sentence), word)]\n",
        "\n",
        "        for candidate in self._extract_known(self._get_edits1(word)):\n",
        "            corrected_sentence = sentence.copy()\n",
        "            corrected_sentence[position] = candidate\n",
        "            candidates.append((self.__get_sentence_probability(corrected_sentence) - self.penalty1, candidate))\n",
        "\n",
        "        for candidate in self._extract_known(self._get_edits2(word)):\n",
        "            corrected_sentence = sentence.copy()\n",
        "            corrected_sentence[position] = candidate\n",
        "            candidates.append((self.__get_sentence_probability(corrected_sentence) - self.penalty2, candidate))\n",
        "\n",
        "        return max(candidates, key=lambda x: x[0])[1]\n",
        "\n",
        "    def _generate_candidates(self, word: str) -> set[str]:\n",
        "        return (self._extract_known(self._get_edits1(word)) or self._extract_known(self._get_edits2(word)) or [word])\n",
        "\n",
        "    def __get_sentence_probability(self, sentence: list[str]) -> float:\n",
        "        \"\"\"\n",
        "        Get probability of whole sentence\n",
        "\n",
        "        Parameters:\n",
        "            sentence (list[str]): The sentence\n",
        "        Returns:\n",
        "            (float): Probability of provided sentence to occure in the text\n",
        "        \"\"\"\n",
        "        probability = 0.0\n",
        "        for k in range(2, self.n):\n",
        "            for i in range(0, len(sentence)-k+1):\n",
        "                ngram = \" \".join(sentence[i:i+k])\n",
        "                ngram_without_last = \" \".join(sentence[i:i+k-1])\n",
        "                probability += log((self.ngram_counter[ngram]+1)/(self.vocab_size + self.ngram_counter[ngram_without_last]))\n",
        "\n",
        "        for word in sentence:\n",
        "            probability += log((self.word_counter[word]+1)/(self.N + self.vocab_size))\n",
        "        return probability\n",
        "\n",
        "temp = CustomSpellCorrector([[\"hello\", \"test\", \"version\", \"hello\"]])\n",
        "print(f\"VOCAB SIZE - {temp.vocab_size}\")\n",
        "print(temp.correct_sentence([\"hello\", \"hello\", \"test\", \"version\"]))"
      ],
      "metadata": {
        "id": "v_AxDWcRulkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be125b9c-56bc-486c-abcf-3c704290d42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE - 3\n",
            "['hello', 'hello', 'test', 'version']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train correctors on a dataset"
      ],
      "metadata": {
        "id": "3-fAz6Hnu_oY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download train dataset\n",
        "%%capture\n",
        "!wget https://downloads.wortschatz-leipzig.de/corpora/eng-simple_wikipedia_2021_300K.tar.gz\n",
        "!tar -xvzf eng-simple_wikipedia_2021_300K.tar.gz"
      ],
      "metadata": {
        "id": "sfFUA36whajp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download train dataset\n",
        "%%capture\n",
        "!wget https://downloads.wortschatz-leipzig.de/corpora/eng_news_2023_300K.tar.gz\n",
        "!tar -xvzf eng_news_2023_300K.tar.gz"
      ],
      "metadata": {
        "id": "dOXqcQMZN0p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "wikipedia_df = pd.read_csv(\"eng-simple_wikipedia_2021_300K/eng-simple_wikipedia_2021_300K-sentences.txt\", sep='\\t', header=None, names=[\"id\", \"sentence\"])\n",
        "news_df = pd.read_csv(\"eng_news_2023_300K/eng_news_2023_300K-sentences.txt\", sep='\\t', header=None, names=[\"id\", \"sentence\"])"
      ],
      "metadata": {
        "id": "HTTeH8BkheKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "def load_to_corpus(df: pd.DataFrame, corpus: list[str]) -> None:\n",
        "    \"\"\"\n",
        "    Load dataset with sentence's row to a text corpus\n",
        "\n",
        "    Parameters:\n",
        "        df (DataFrame): DataFrame that has sentence row\n",
        "        corpus (list[str]): Text corpus to extend\n",
        "    \"\"\"\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "        sentence = row[\"sentence\"]\n",
        "        words = re.findall(r'\\w+', sentence.lower())\n",
        "        corpus.append(words)\n",
        "\n",
        "\n",
        "train_corpus = []\n",
        "load_to_corpus(wikipedia_df, train_corpus)\n",
        "load_to_corpus(news_df, train_corpus)\n",
        "\n",
        "train_corpus[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA9t8NIglY9G",
        "outputId": "5d7ed6ca-710b-4382-ba4b-9613f6e7211c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 292455/292455 [00:20<00:00, 13942.38it/s]\n",
            "100%|██████████| 249986/249986 [00:18<00:00, 13244.98it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'coin', 'struck', 'only', 'in', 'proof']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norvig_spell_corrector = NorvigSpellCorrector(train_corpus)\n",
        "custom_spell_corrector = CustomSpellCorrector(train_corpus, penalty1= 4.9, penalty2 = 12.1)"
      ],
      "metadata": {
        "id": "-EMF8Xdkcxlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "check_text = [\n",
        "                [\"bleu\", \"lilte\", \"boy\", \"really\", \"loves\", \"appls\"],\n",
        "                [\"he\", \"ws\", \"scared\", \"uf\", \"snkes\"]\n",
        "              ]\n",
        "\n",
        "print(f\"Norvig's solution: {norvig_spell_corrector.correct_text(check_text)}\")\n",
        "print(f\"Custom spell corrector: {custom_spell_corrector.correct_text(check_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKLLth24nBEX",
        "outputId": "4e9942e8-1e2f-4212-bab2-2b645948f58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norvig's solution: [['bleu', 'lite', 'boy', 'really', 'loves', 'apple'], ['he', 'ws', 'scared', 'uf', 'snakes']]\n",
            "Custom spell corrector: [['blue', 'little', 'boy', 'really', 'loves', 'apple'], ['he', 'was', 'scared', 'of', 'snakes']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "### Decisions\n",
        "#### <font color='yellow'> Implementing language model with trigrams</font>\n",
        "Reason: I decided to implement a language model using trigrams for improved accuracy without significant slowdown in both training and inference for spell checking.\n",
        "\n",
        "#### <font color='yellow'> Training on Wikipedia and News articles </font>\n",
        "Reason: I utilized text corpora from Wikipedia and news articles for training purposes. These diverse sources cover a wide range of topics and domains, making them ideal for training a general-purpose spell checker. Additionally, the texts are meticulously reviewed by correctors, ensuring they are error-free and devoid of misspellings.\n",
        "\n",
        "#### <font color='yellow'> Assigning specific penalties to edits  </font>\n",
        "Reason: I have incorporated specific penalties to reduce the occurrence of false corrections. In my strategy, I have assigned a penalty of 4.9 for single edits and 12.1 for two consecutive edits of a word. After conducting various experiments with different penalty values, these particular settings have proven to deliver the most high fix rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I did not generate test set but used one from Hugging face https://huggingface.co/datasets/vishnun/SpellGram for more fair results**"
      ],
      "metadata": {
        "id": "99oX6XaP4vJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading test set\n",
        "!wget https://huggingface.co/datasets/vishnun/SpellGram/raw/main/train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1uCM6TBnIJP",
        "outputId": "9f516b02-e012-449c-bc3b-bde0c235871e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-06 20:12:34--  https://huggingface.co/datasets/vishnun/SpellGram/raw/main/train.csv\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.55, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4489429 (4.3M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]   4.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-06 20:12:34 (43.8 MB/s) - ‘train.csv’ saved [4489429/4489429]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwZWaX9VVs7B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9dcbeab2-91a3-48a2-fc87-bb21200e98ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        source  \\\n",
              "0        rate the silent upeaker four out oe 6   \n",
              "1    please find me tqe gork tqe bfrning sorld   \n",
              "2  three friendl afe relaxing uround the tsble   \n",
              "3                            what dm they want   \n",
              "4           man in tan aat working with stones   \n",
              "\n",
              "                                        target  \n",
              "0        rate the silent speaker four out of 6  \n",
              "1    please find me the work the burning world  \n",
              "2  three friends are relaxing around the table  \n",
              "3                            what do they want  \n",
              "4           man in tan hat working with stones  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b548d2ed-2144-49a2-a6ca-69dce27a358b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rate the silent upeaker four out oe 6</td>\n",
              "      <td>rate the silent speaker four out of 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>please find me tqe gork tqe bfrning sorld</td>\n",
              "      <td>please find me the work the burning world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>three friendl afe relaxing uround the tsble</td>\n",
              "      <td>three friends are relaxing around the table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what dm they want</td>\n",
              "      <td>what do they want</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man in tan aat working with stones</td>\n",
              "      <td>man in tan hat working with stones</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b548d2ed-2144-49a2-a6ca-69dce27a358b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b548d2ed-2144-49a2-a6ca-69dce27a358b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b548d2ed-2144-49a2-a6ca-69dce27a358b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85206971-f703-4a83-bdc1-16c411d3f109\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85206971-f703-4a83-bdc1-16c411d3f109')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85206971-f703-4a83-bdc1-16c411d3f109 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40000,\n        \"samples\": [\n          \"to thw south of thw station thw railway line is elevated on a viaduct\",\n          \"hhe station is situated at hhe eastern end of hhe high street\",\n          \"the unemployment rate in consett became double the national average\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39899,\n        \"samples\": [\n          \"two asian men working on the side of a street with parked cars\",\n          \"and was i not wise he said with complacency\",\n          \"its home field was capilano stadium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"train.csv\")\n",
        "test_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_spell_corrector(test_df: pd.DataFrame, spell_corrector: AbstractSpellCorrector):\n",
        "    \"\"\"\n",
        "    Evaluates provided spell corrector by `fix-rate` and `broken` metrics\n",
        "    \"\"\"\n",
        "    true_fixed_errors = 0\n",
        "    false_fixed_errors = 0\n",
        "    errors = 0\n",
        "    no_errors = 0\n",
        "\n",
        "    for index, sample in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
        "        source = re.findall(r'\\w+', sample[\"source\"].lower())\n",
        "        target = re.findall(r'\\w+', sample[\"target\"].lower())\n",
        "\n",
        "        corrected = spell_corrector.correct_sentence(source)\n",
        "        for i in range(len(source)):\n",
        "            if source[i] != target[i]:\n",
        "                errors += 1\n",
        "                if corrected[i] == target[i]:\n",
        "                    true_fixed_errors += 1\n",
        "            else:\n",
        "                no_errors += 1\n",
        "                if corrected[i] != source[i]:\n",
        "                    false_fixed_errors += 1\n",
        "\n",
        "    return true_fixed_errors / errors, false_fixed_errors / no_errors\n",
        "\n",
        "n_subset = 2000 # How much samples e will take to test\n",
        "\n",
        "fix_rate, broken = evaluate_spell_corrector(test_df.head(n_subset), norvig_spell_corrector)\n",
        "print()\n",
        "print(\"NORVIG's SPELL CORRECTOR:\")\n",
        "print(f\"FIX RATE: {fix_rate}\")\n",
        "print(f\"BROKEN: {broken}\")\n",
        "\n",
        "fix_rate, broken = evaluate_spell_corrector(test_df.head(n_subset), custom_spell_corrector)\n",
        "print()\n",
        "print(\"MY CUSTOM SPELL CORRECTOR:\")\n",
        "print(f\"FIX RATE: {fix_rate}\")\n",
        "print(f\"BROKEN: {broken}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR8gKV5tnPX7",
        "outputId": "208a01da-d2b0-4bb0-aab5-b9a26640eb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [02:18<00:00, 14.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NORVIG's SPELL CORRECTOR:\n",
            "FIX RATE: 0.4969631236442516\n",
            "BROKEN: 0.01782602868248224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [29:44<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MY CUSTOM SPELL CORRECTOR:\n",
            "FIX RATE: 0.7067245119305857\n",
            "BROKEN: 0.04268864763436537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"lime\">As you can see, my solution works 20% better for fix rate, while the \"broken\" metric has increased by only about 2.5%</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cCL03A0CsVG7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xrdwmhQKElg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}